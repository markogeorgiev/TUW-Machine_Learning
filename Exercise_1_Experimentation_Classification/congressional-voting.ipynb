{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MLP for the Congressional Voting Dataset",
   "id": "ec5503863aa185ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing the Data",
   "id": "f38f9dd65bb36e36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:30:35.759235Z",
     "start_time": "2025-04-24T17:30:24.515947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv('all_datasets/CongressionalVotingID.shuf.lrn.csv')\n",
    "df = df.drop(columns=['ID'])"
   ],
   "id": "4f2cd7862a2f0b6e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:30:35.783370Z",
     "start_time": "2025-04-24T17:30:35.773241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"class\"] = label_encoder.fit_transform(df[\"class\"])"
   ],
   "id": "a53686ef45519cd7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:30:36.354298Z",
     "start_time": "2025-04-24T17:30:36.316373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Map vote values\n",
    "vote_map = {\"y\": 1, \"n\": 0, \"unknown\": 0.5}\n",
    "for col in df.columns[1:]:\n",
    "    df[col] = df[col].map(vote_map)\n",
    "\n",
    "X = df.drop(columns=[\"class\"]).values.astype(np.float32)\n",
    "y = df[\"class\"].values.astype(np.int64)"
   ],
   "id": "6a0b9a650534e2e0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:30:55.053777Z",
     "start_time": "2025-04-24T17:30:36.394817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "                nn.Linear(input_dim, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 8),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(8, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "split_ratios = [0.5, 0.3, 0.2, 0.1]\n",
    "\n",
    "for split in split_ratios:\n",
    "    print(f\"\\n--- Evaluating {int((1 - split) * 100)}/{int(split * 100)} Train/Test Split ---\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42, stratify=y)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    y_train_tensor = torch.tensor(y_train)\n",
    "    X_test_tensor = torch.tensor(X_test)\n",
    "    y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "    model = MLP(X.shape[1])\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_train_tensor)\n",
    "        loss = loss_fn(logits, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = torch.argmax(model(X_test_tensor), dim=1).numpy()\n",
    "        y_true = y_test_tensor.numpy()\n",
    "\n",
    "        acc = accuracy_score(y_true, preds)\n",
    "        prec = precision_score(y_true, preds, zero_division=0)\n",
    "        rec = recall_score(y_true, preds, zero_division=0)\n",
    "        f1 = f1_score(y_true, preds, zero_division=0)\n",
    "\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall:    {rec:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")"
   ],
   "id": "ec9a15114fe57494",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating 50/50 Train/Test Split ---\n",
      "Accuracy:  0.9358\n",
      "Precision: 0.8800\n",
      "Recall:    0.9778\n",
      "F1 Score:  0.9263\n",
      "\n",
      "--- Evaluating 70/30 Train/Test Split ---\n",
      "Accuracy:  0.9848\n",
      "Precision: 1.0000\n",
      "Recall:    0.9643\n",
      "F1 Score:  0.9818\n",
      "\n",
      "--- Evaluating 80/20 Train/Test Split ---\n",
      "Accuracy:  0.9773\n",
      "Precision: 1.0000\n",
      "Recall:    0.9444\n",
      "F1 Score:  0.9714\n",
      "\n",
      "--- Evaluating 90/10 Train/Test Split ---\n",
      "Accuracy:  0.9545\n",
      "Precision: 1.0000\n",
      "Recall:    0.8889\n",
      "F1 Score:  0.9412\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing out different MLPs",
   "id": "a85a09cc9470ca6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T18:31:25.092505Z",
     "start_time": "2025-04-24T18:31:20.627403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv('all_datasets/CongressionalVotingID.shuf.lrn.csv')\n",
    "df = df.drop(columns=['ID'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"class\"] = label_encoder.fit_transform(df[\"class\"])\n",
    "\n",
    "# Map vote values\n",
    "vote_map = {\"y\": 1, \"n\": 0, \"unknown\": 0.5}\n",
    "for col in df.columns[1:]:\n",
    "    df[col] = df[col].map(vote_map)\n",
    "\n",
    "X = df.drop(columns=[\"class\"]).values.astype(np.float32)\n",
    "y = df[\"class\"].values.astype(np.int64)\n",
    "\n",
    "# Split once using 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "# Define different model architectures\n",
    "model_architectures = [\n",
    "    nn.Sequential(\n",
    "        nn.Linear(X.shape[1], 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 2),\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(X.shape[1], 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 2),\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(X.shape[1], 32),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(32, 16),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(16, 2),\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(X.shape[1], 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(64, 2),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for i, architecture in enumerate(model_architectures, 1):\n",
    "    print(f\"\\n--- Evaluating Model Architecture {i} ---\")\n",
    "\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.model = architecture\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "\n",
    "    model = MLP()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_train_tensor)\n",
    "        loss = loss_fn(logits, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = torch.argmax(model(X_test_tensor), dim=1).numpy()\n",
    "        y_true = y_test_tensor.numpy()\n",
    "\n",
    "        acc = accuracy_score(y_true, preds)\n",
    "        prec = precision_score(y_true, preds, zero_division=0)\n",
    "        rec = recall_score(y_true, preds, zero_division=0)\n",
    "        f1 = f1_score(y_true, preds, zero_division=0)\n",
    "\n",
    "        results.append((f\"MLP{i}\", acc, prec, rec, f1))\n",
    "\n",
    "        # Print results in table format\n",
    "print(\"\\nMODEL\\tAccuracy\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "for model_name, acc, prec, rec, f1 in results:\n",
    "    print(f\"{model_name}\\t{acc:.4f}\\t\\t{prec:.4f}\\t\\t{rec:.4f}\\t\\t{f1:.4f}\")"
   ],
   "id": "4056d61d0bae46ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model Architecture 1 ---\n",
      "\n",
      "--- Evaluating Model Architecture 2 ---\n",
      "\n",
      "--- Evaluating Model Architecture 3 ---\n",
      "\n",
      "--- Evaluating Model Architecture 4 ---\n",
      "\n",
      "MODEL\tAccuracy\tPrecision\tRecall\t\tF1-Score\n",
      "MLP1\t0.9848\t\t1.0000\t\t0.9643\t\t0.9818\n",
      "MLP2\t0.9848\t\t1.0000\t\t0.9643\t\t0.9818\n",
      "MLP3\t0.9848\t\t1.0000\t\t0.9643\t\t0.9818\n",
      "MLP4\t0.9697\t\t0.9643\t\t0.9643\t\t0.9643\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2d8e611e4068fc4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Kaggle Code",
   "id": "41c9a3f2cf90dec8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T18:29:34.742957Z",
     "start_time": "2025-04-24T18:29:33.542220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load training data\n",
    "df_train = pd.read_csv('all_datasets/CongressionalVotingID.shuf.lrn.csv')\n",
    "df_train = df_train.drop(columns=['ID'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_train[\"class\"] = label_encoder.fit_transform(df_train[\"class\"])\n",
    "\n",
    "vote_map = {\"y\": 1, \"n\": 0, \"unknown\": 0.5}\n",
    "for col in df_train.columns[1:]:\n",
    "    df_train[col] = df_train[col].map(vote_map)\n",
    "\n",
    "X_train = df_train.drop(columns=[\"class\"]).values.astype(np.float32)\n",
    "y_train = df_train[\"class\"].values.astype(np.int64)\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv('all_datasets/CongressionalVotingID.shuf.tes.csv')\n",
    "test_ids = df_test[\"ID\"].values\n",
    "df_test = df_test.drop(columns=[\"ID\"])\n",
    "\n",
    "for col in df_test.columns:\n",
    "    df_test[col] = df_test[col].map(vote_map)\n",
    "\n",
    "X_test = df_test.values.astype(np.float32)\n",
    "\n",
    "\n",
    "# Define MLP1\n",
    "class MLP1(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "\n",
    "model = MLP1(X_train.shape[1])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(X_train_tensor)\n",
    "    loss = loss_fn(logits, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predict on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_tensor = torch.argmax(model(X_test_tensor), dim=1)\n",
    "    preds = preds_tensor.numpy()\n",
    "\n",
    "# Save submission v2: decoded predictions\n",
    "decoded_preds = label_encoder.inverse_transform(preds)\n",
    "df_submission_v2 = pd.DataFrame({\"ID\": test_ids, \"class\": decoded_preds})\n",
    "df_submission_v2.to_csv(\"submission_mlp_v2.csv\", index=False)\n",
    "\n",
    "print(\"Submissions saved as 'submission_mlp_v2.csv'\")"
   ],
   "id": "956663deeeb5855b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissions saved as 'submission_mlp_v2.csv'\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross Validation\n",
    "using the best model from the previous section"
   ],
   "id": "6b7c4490ea245531"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T19:24:45.573638Z",
     "start_time": "2025-04-24T19:24:41.995105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define MLP as a class for re-initialization\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Set up\n",
    "df = pd.read_csv('all_datasets/CongressionalVotingID.shuf.lrn.csv')\n",
    "df = df.drop(columns=['ID'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"class\"] = label_encoder.fit_transform(df[\"class\"])\n",
    "\n",
    "# Map vote values\n",
    "vote_map = {\"y\": 1, \"n\": 0, \"unknown\": 0.5}\n",
    "for col in df.columns[1:]:\n",
    "    df[col] = df[col].map(vote_map)\n",
    "\n",
    "X = df.drop(columns=[\"class\"]).values.astype(np.float32)\n",
    "y = df[\"class\"].values.astype(np.int64)\n",
    "def run_cv(X, y, n_splits):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    all_results = []\n",
    "\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = len(np.unique(y))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"\\n[Fold {fold}/{n_splits}]\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "        model = MLP(input_dim, output_dim).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "        # Training\n",
    "        for epoch in range(200):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = loss_fn(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_test_tensor).argmax(dim=1).cpu().numpy()\n",
    "            y_true = y_test_tensor.cpu().numpy()\n",
    "\n",
    "            acc = accuracy_score(y_true, preds)\n",
    "            prec = precision_score(y_true, preds, average='macro', zero_division=0)\n",
    "            rec = recall_score(y_true, preds, average='macro', zero_division=0)\n",
    "            f1 = f1_score(y_true, preds, average='macro', zero_division=0)\n",
    "\n",
    "            all_results.append((acc, prec, rec, f1))\n",
    "\n",
    "    accs, precs, recs, f1s = zip(*all_results)\n",
    "    print(f\"\\n=== {n_splits}-Fold CV Results ===\")\n",
    "    print(f\"Accuracy:  {np.mean(accs):.4f}\")\n",
    "    print(f\"Precision: {np.mean(precs):.4f}\")\n",
    "    print(f\"Recall:    {np.mean(recs):.4f}\")\n",
    "    print(f\"F1 Score:  {np.mean(f1s):.4f}\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "# Run 5-fold and 10-fold CV\n",
    "run_cv(X, y, n_splits=5)\n",
    "run_cv(X, y, n_splits=10)"
   ],
   "id": "873f6cfc014fa0f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 1/5]\n",
      "\n",
      "[Fold 2/5]\n",
      "\n",
      "[Fold 3/5]\n",
      "\n",
      "[Fold 4/5]\n",
      "\n",
      "[Fold 5/5]\n",
      "\n",
      "=== 5-Fold CV Results ===\n",
      "Accuracy:  0.9680\n",
      "Precision: 0.9666\n",
      "Recall:    0.9676\n",
      "F1 Score:  0.9670\n",
      "==============================\n",
      "\n",
      "[Fold 1/10]\n",
      "\n",
      "[Fold 2/10]\n",
      "\n",
      "[Fold 3/10]\n",
      "\n",
      "[Fold 4/10]\n",
      "\n",
      "[Fold 5/10]\n",
      "\n",
      "[Fold 6/10]\n",
      "\n",
      "[Fold 7/10]\n",
      "\n",
      "[Fold 8/10]\n",
      "\n",
      "[Fold 9/10]\n",
      "\n",
      "[Fold 10/10]\n",
      "\n",
      "=== 10-Fold CV Results ===\n",
      "Accuracy:  0.9634\n",
      "Precision: 0.9651\n",
      "Recall:    0.9621\n",
      "F1 Score:  0.9623\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
