{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MLP for Student Dropout and Academic Success Dataset",
   "id": "c193d33c4f52ed0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing the Data",
   "id": "8205b15e9d4fc64f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:44:53.016819Z",
     "start_time": "2025-04-24T17:44:50.037384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('all_datasets/student_droupout_data.csv', sep=\";\")\n",
    "\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]"
   ],
   "id": "c86384677b551782",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:44:53.050711Z",
     "start_time": "2025-04-24T17:44:53.021463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols += [\n",
    "    \"Marital status\", \"Application mode\", \"Application order\", \"Course\",\n",
    "    \"Daytime/evening attendance\\t\", \"Previous qualification\", \"Nacionality\",\n",
    "    \"Mother's qualification\", \"Father's qualification\", \"Mother's occupation\",\n",
    "    \"Father's occupation\", \"Displaced\", \"Educational special needs\", \"Debtor\",\n",
    "    \"Tuition fees up to date\", \"Gender\", \"Scholarship holder\", \"International\"\n",
    "]\n",
    "categorical_cols = list(set(categorical_cols))\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "X = X.fillna(0)"
   ],
   "id": "18e36997ab1ba200",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:44:57.261407Z",
     "start_time": "2025-04-24T17:44:57.256834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ],
   "id": "2cce0a9f0d9983cc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:44:58.295159Z",
     "start_time": "2025-04-24T17:44:58.288942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Train/test split ratios to evaluate\n",
    "split_ratios = [0.5, 0.3, 0.2, 0.1]\n"
   ],
   "id": "9fa805bb63c8ca2d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:45:14.828065Z",
     "start_time": "2025-04-24T17:44:59.445826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for split in split_ratios:\n",
    "    print(f\"\\n--- Evaluating {int((1-split)*100)}/{int(split*100)} Train/Test Split ---\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=split, random_state=0, stratify=y_encoded)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = len(np.unique(y_encoded))\n",
    "    model = MLP(input_dim, output_dim)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    epochs = 1500\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_train_tensor)\n",
    "        loss = criterion(logits, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test_tensor).argmax(dim=1).numpy()\n",
    "        y_true = y_test_tensor.numpy()\n",
    "\n",
    "        acc = accuracy_score(y_true, preds)\n",
    "        prec = precision_score(y_true, preds, average='macro', zero_division=0)\n",
    "        rec = recall_score(y_true, preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, preds, average='macro', zero_division=0)\n",
    "\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall:    {rec:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")"
   ],
   "id": "450517fc903d81e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating 50/50 Train/Test Split ---\n",
      "Accuracy:  0.7622\n",
      "Precision: 0.7028\n",
      "Recall:    0.6834\n",
      "F1 Score:  0.6900\n",
      "\n",
      "--- Evaluating 70/30 Train/Test Split ---\n",
      "Accuracy:  0.7508\n",
      "Precision: 0.6832\n",
      "Recall:    0.6707\n",
      "F1 Score:  0.6754\n",
      "\n",
      "--- Evaluating 80/20 Train/Test Split ---\n",
      "Accuracy:  0.7661\n",
      "Precision: 0.7081\n",
      "Recall:    0.6915\n",
      "F1 Score:  0.6979\n",
      "\n",
      "--- Evaluating 90/10 Train/Test Split ---\n",
      "Accuracy:  0.7675\n",
      "Precision: 0.7072\n",
      "Recall:    0.6860\n",
      "F1 Score:  0.6934\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing out different MLPs",
   "id": "9899efb826e6b395"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T19:01:13.901964Z",
     "start_time": "2025-04-24T19:00:41.266301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('all_datasets/student_droupout_data.csv', sep=\";\")\n",
    "\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols += [\n",
    "    \"Marital status\", \"Application mode\", \"Application order\", \"Course\",\n",
    "    \"Daytime/evening attendance\\t\", \"Previous qualification\", \"Nacionality\",\n",
    "    \"Mother's qualification\", \"Father's qualification\", \"Mother's occupation\",\n",
    "    \"Father's occupation\", \"Displaced\", \"Educational special needs\", \"Debtor\",\n",
    "    \"Tuition fees up to date\", \"Gender\", \"Scholarship holder\", \"International\"\n",
    "]\n",
    "categorical_cols = list(set(categorical_cols))\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 70/30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=0, stratify=y_encoded)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Define architectures\n",
    "input_dim = X.shape[1]\n",
    "output_dim = len(np.unique(y_encoded))\n",
    "model_architectures = [\n",
    "    nn.Sequential(\n",
    "        nn.Linear(input_dim, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, output_dim)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(input_dim, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, output_dim)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(input_dim, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(64, output_dim)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(input_dim, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, output_dim)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train + Evaluate\n",
    "results = []\n",
    "\n",
    "for i, architecture in enumerate(model_architectures, 1):\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.model = architecture\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "    model = MLP()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    for epoch in range(1500):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test_tensor).argmax(dim=1).numpy()\n",
    "        y_true = y_test_tensor.numpy()\n",
    "\n",
    "        acc = accuracy_score(y_true, preds)\n",
    "        prec = precision_score(y_true, preds, average='macro', zero_division=0)\n",
    "        rec = recall_score(y_true, preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, preds, average='macro', zero_division=0)\n",
    "\n",
    "        results.append((f\"MLP{i}\", acc, prec, rec, f1))\n",
    "\n",
    "# Print table\n",
    "print(\"\\nMODEL\\tAccuracy\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "for model_name, acc, prec, rec, f1 in results:\n",
    "    print(f\"{model_name}\\t{acc:.4f}\\t\\t{prec:.4f}\\t\\t{rec:.4f}\\t\\t{f1:.4f}\")\n"
   ],
   "id": "390e95f8a90d5026",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL\tAccuracy\tPrecision\tRecall\t\tF1-Score\n",
      "MLP1\t0.7304\t\t0.6710\t\t0.6677\t\t0.6692\n",
      "MLP2\t0.7056\t\t0.6361\t\t0.6360\t\t0.6361\n",
      "MLP3\t0.7613\t\t0.6988\t\t0.6849\t\t0.6903\n",
      "MLP4\t0.7440\t\t0.6796\t\t0.6713\t\t0.6748\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross Validation\n",
    "using the best model from the previous section"
   ],
   "id": "fadc937c7f0fcfde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T19:55:00.090862Z",
     "start_time": "2025-04-24T19:40:05.658947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('all_datasets/student_droupout_data.csv', sep=\";\")\n",
    "\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols += [\n",
    "    \"Marital status\", \"Application mode\", \"Application order\", \"Course\",\n",
    "    \"Daytime/evening attendance\\t\", \"Previous qualification\", \"Nacionality\",\n",
    "    \"Mother's qualification\", \"Father's qualification\", \"Mother's occupation\",\n",
    "    \"Father's occupation\", \"Displaced\", \"Educational special needs\", \"Debtor\",\n",
    "    \"Tuition fees up to date\", \"Gender\", \"Scholarship holder\", \"International\"\n",
    "]\n",
    "categorical_cols = list(set(categorical_cols))\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define custom architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Cross-validation function\n",
    "def run_cv(X, y, n_splits):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = len(np.unique(y))\n",
    "    results = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"\\n[Fold {fold}/{n_splits}]\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "        model = MLP(input_dim, output_dim).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "        for epoch in range(1500):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_test_tensor).argmax(dim=1).cpu().numpy()\n",
    "            y_true = y_test_tensor.cpu().numpy()\n",
    "\n",
    "            acc = accuracy_score(y_true, preds)\n",
    "            prec = precision_score(y_true, preds, average='macro', zero_division=0)\n",
    "            rec = recall_score(y_true, preds, average='macro', zero_division=0)\n",
    "            f1 = f1_score(y_true, preds, average='macro', zero_division=0)\n",
    "\n",
    "            results.append((acc, prec, rec, f1))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run 5-fold and 10-fold CV\n",
    "results_5fold = run_cv(X_scaled, y_encoded, n_splits=5)\n",
    "results_10fold = run_cv(X_scaled, y_encoded, n_splits=10)\n",
    "\n",
    "# Print results\n",
    "def print_results(results, label):\n",
    "    accs, precs, recs, f1s = zip(*results)\n",
    "    print(f\"\\n=== {label} Results ===\")\n",
    "    print(\"MODEL\\tAccuracy\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "    print(f\"{label}\\t{np.mean(accs):.4f}\\t\\t{np.mean(precs):.4f}\\t\\t{np.mean(recs):.4f}\\t\\t{np.mean(f1s):.4f}\")\n",
    "\n",
    "print_results(results_5fold, \"5-Fold\")\n",
    "print_results(results_10fold, \"10-Fold\")"
   ],
   "id": "81d8aca7915a1aa9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold 1/5]\n",
      "\n",
      "[Fold 2/5]\n",
      "\n",
      "[Fold 3/5]\n",
      "\n",
      "[Fold 4/5]\n",
      "\n",
      "[Fold 5/5]\n",
      "\n",
      "[Fold 1/10]\n",
      "\n",
      "[Fold 2/10]\n",
      "\n",
      "[Fold 3/10]\n",
      "\n",
      "[Fold 4/10]\n",
      "\n",
      "[Fold 5/10]\n",
      "\n",
      "[Fold 6/10]\n",
      "\n",
      "[Fold 7/10]\n",
      "\n",
      "[Fold 8/10]\n",
      "\n",
      "[Fold 9/10]\n",
      "\n",
      "[Fold 10/10]\n",
      "\n",
      "=== 5-Fold Results ===\n",
      "MODEL\tAccuracy\tPrecision\tRecall\t\tF1-Score\n",
      "5-Fold\t0.7547\t\t0.6892\t\t0.6741\t\t0.6789\n",
      "\n",
      "=== 10-Fold Results ===\n",
      "MODEL\tAccuracy\tPrecision\tRecall\t\tF1-Score\n",
      "10-Fold\t0.7568\t\t0.6954\t\t0.6777\t\t0.6837\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a1697b7abd886bf6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
